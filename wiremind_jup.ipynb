{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a9107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd0e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_wiremind.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3e770c",
   "metadata": {},
   "source": [
    "## Checking for Missing Values\n",
    "We need to confirm that there are no missing values in the dataset before proceeding with further analysis. This ensures that we do not run into errors during the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1052af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49c4e2f",
   "metadata": {},
   "source": [
    "No missing values, great! So let's start with the EDA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d827289",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bcd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting basic distributions to better understand whats inside the dataset \n",
    "numerical_columns = ['ChargeableWeight', 'Revenue', 'Pieces']\n",
    "for col in numerical_columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(df[col], bins=30, color='skyblue', edgecolor='black')\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Plotting the top 10 categorical feature distributions\n",
    "categorical_columns = ['AgentCode', 'ProductCode']\n",
    "for col in categorical_columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df[col].value_counts().nlargest(10).plot(kind='bar', color='lightgreen')\n",
    "    plt.title(f'Frequency of {col} (Top 10)')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a31a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a465cce2",
   "metadata": {},
   "source": [
    "Generated a summary of the dataset with rounded values to get an overview of the central tendency and distribution without decimals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26030c6a",
   "metadata": {},
   "source": [
    "Checking the column names in the dataset to understand the available features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ffcdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6c3dad",
   "metadata": {},
   "source": [
    "Counting the number of unique values for each column to identify categorical features and assess the variability of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee88ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(i, len(df[i].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e1ad54",
   "metadata": {},
   "source": [
    "##### we can see that we have only 1 year for FlownYear (2017), 1 destination for DestinationCode so we can remove them because they won't help our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06cf114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of the original DataFrame to preserve the original data\n",
    "new_df = df.copy()\n",
    "#drop unnecessary columns that are not needed for analysis\n",
    "new_df = new_df.drop([\"DocumentRatingSource\",\"FlownYear\",\"DestinationCode\" ], axis =1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db527407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the target variable as revenue per ChargeableWeight\n",
    "new_df[\"target\"] = new_df[\"Revenue\"]/ new_df[\"ChargeableWeight\"]\n",
    "#display the first few rows to verify the new 'target' column\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cb9162",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.describe().round(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb691f",
   "metadata": {},
   "source": [
    "Summary statistics of the modified dataset to assess the updated features and new target variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf6155",
   "metadata": {},
   "source": [
    "### MONTHS ANALYSIS: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8293b729",
   "metadata": {},
   "source": [
    "Calculating the average Chargeable Weight, Revenue, and Target for each month to understand trends over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3435d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_avg = new_df.groupby('FlownMonth')[[\"ChargeableWeight\", 'Revenue', 'target']].mean()\n",
    "month_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e36fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of shipments for each month\n",
    "monthly_shipments = new_df['FlownMonth'].groupby(df['FlownMonth']).size()\n",
    "print(monthly_shipments)\n",
    "#calculate the percentage of shipments for each month\n",
    "monthly_percentage = (monthly_shipments / len(new_df)) * 100\n",
    "\n",
    "monthly_percentage.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3008f265",
   "metadata": {},
   "source": [
    "The output shows that the distribution of shipments across different months is relatively balanced, with each month contributing between 31.49% and 34.38% of the total shipments. This suggests that there is no **major** seasonality effect in shipment frequency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601183dd",
   "metadata": {},
   "source": [
    "Visualizing the average revenue and average revenue per kg (target) by month to identify any trends or seasonality effects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a788c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['FlownMonth', 'Revenue', 'Pieces']\n",
    "titles = ['Total Shipments by Flown Month', 'Total Revenue by Flown Month', 'Average Number of Pieces Shipped by Month']\n",
    "y_labels = ['Total Shipments', 'Total Revenue', 'Average Pieces']\n",
    "colors = ['g', 'b', 'r']\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    if metric == 'FlownMonth':\n",
    "        # Count the number of shipments per month for the first graph\n",
    "        df_grouped_by_month = df.groupby('FlownMonth').size()\n",
    "    elif metric == 'Pieces' and i == 2:\n",
    "        # Calculate the average number of pieces shipped by month for the third graph\n",
    "        df_grouped_by_month = df.groupby('FlownMonth')[metric].mean()\n",
    "    else:\n",
    "        df_grouped_by_month = df.groupby('FlownMonth')[metric].sum()\n",
    "    \n",
    "    df_grouped_by_month.plot(kind='line', marker='o', color=colors[i])\n",
    "    plt.title(titles[i])\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel(y_labels[i])\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92acd02",
   "metadata": {},
   "source": [
    "### Total Shipments and Revenue Trends:\n",
    "November shows the highest total number of shipments and revenue, followed by October, with September having the lowest figures. This indicates that November might be a peak period, potentially due to seasonal demand or promotional activities. \n",
    "\n",
    "We can also see that the average number of pieces shipped by month is the lowest in october, we will have to conduct another analysis to see if the number of pieces has a role to play with the total weight of each shipment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31afee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "monthly_weight_mean = new_df.groupby('FlownMonth')['ChargeableWeight'].mean()\n",
    "#plot for average revenue by month\n",
    "ax[0].bar(month_avg.index, month_avg['Revenue'], color='skyblue')\n",
    "ax[0].set_title('Average Revenue by Month')\n",
    "ax[0].set_ylabel('Average Revenue')\n",
    "\n",
    "#plot for average revenue per kg (target = revenue/chargeable weight)\n",
    "ax[1].bar(month_avg.index, month_avg['target'], color='orange')\n",
    "ax[1].set_title('Average Revenue per kg (Target) by Month')\n",
    "ax[1].set_ylabel('Average Revenue per kg')\n",
    "\n",
    "ax[2].bar(monthly_weight_mean.index, monthly_weight_mean, color='green')\n",
    "ax[2].set_title('Average Chargeable Weight by Month')\n",
    "ax[2].set_ylabel('Average Chargeable Weight (kg)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303413f1",
   "metadata": {},
   "source": [
    "### Global Analysis of Shipment and Revenue Trends\n",
    "\n",
    "The visualizations provide an initial overview of the shipment and revenue patterns across the months of September, October, and November. Here's a summary of the observations:\n",
    "\n",
    "\n",
    "   \n",
    "insights:\n",
    "\n",
    "1. **Average Revenue and Revenue per kg**:\n",
    "   - The average revenue per shipment is also the highest in November, aligning with the total revenue pattern. However, the average revenue per kg in November is lower compared to October and September. \n",
    "\n",
    "2. \n",
    "we ship fewer pieces in october (previous cell 3rd plot) but with the new graphs we can see that the average revenue per kg is the highest in october and that the average weight per shipment is also higher in october which might mean that in october they ship heavier items (pieces) that are more expensive.\n",
    "\n",
    "3. **This could indicate that shipments in November are larger in volume but involve lower pricing per unit weight.**\n",
    "\n",
    "\n",
    "### Next Steps\n",
    "To gain deeper insights into these patterns, further analysis will be conducted focusing on:\n",
    "   - **Cargo Type**: Understanding which cargo types dominate during these months and how they impact overall revenue and efficiency.\n",
    "   - **Product Type**: Exploring the specific products shipped and their influence on revenue per kg and shipment volume.\n",
    "   - **Delivery Agents**: Investigating how different delivery agents contribute to these patterns, which could reveal whether certain agents specialize in specific types of cargo or regions.\n",
    "\n",
    "These additional dimensions will help refine the analysis and provide more targeted explanations for the observed trends.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee181c",
   "metadata": {},
   "source": [
    "### CARGO TYPE ANALYSIS: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ba3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "ax = sns.countplot(data=df, x='FlownMonth', hue='CargoType', palette='viridis')\n",
    "\n",
    "# for loop to exactly see the number of different type of cargotype shipment made per month\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'baseline', \n",
    "                fontsize=12, color='black', xytext = (0, 5), \n",
    "                textcoords = 'offset points')\n",
    "\n",
    "#adding titles and labels\n",
    "plt.title('Number of Shipments per Month by CargoType')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Shipments')\n",
    "plt.legend(title='CargoType')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Grouping the dataset by cargotype to calculate the average target for each type\n",
    "average_target_per_cargo = new_df.groupby('CargoType')['target'].mean().sort_values()\n",
    "\n",
    "# Plotting the average target per cargo type\n",
    "plt.figure(figsize=(15, 6))\n",
    "average_target_per_cargo.plot(kind='barh', color='skyblue')\n",
    "plt.title('Average Revenue per kg (Target) by Cargo Type')\n",
    "plt.xlabel('Average Revenue per kg')\n",
    "plt.ylabel('Cargo Type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad9183",
   "metadata": {},
   "source": [
    "### Link Between Shipment Volume and Revenue per kg by Cargo Type\n",
    "\n",
    "The two graphs provide complementary insights into the shipment patterns and the revenue efficiency per kilogram across different cargo types. Here's how they are connected:\n",
    "\n",
    "1. **Shipment Volume by Cargo Type**:\n",
    "   - The first graph shows the number of shipments per month for each cargo type. It is evident that **ZZZ** dominates the shipment volume in all months, with significantly higher counts compared to **YYY** and **XXX**. This suggests that **ZZZ** is the most commonly shipped cargo type, contributing the most to the overall shipment count.\n",
    "\n",
    "2. **Revenue Efficiency per kg by Cargo Type**:\n",
    "   - The second graph displays the average revenue per kilogram for each cargo type. Interestingly, **YYY** has the highest revenue per kilogram, while **ZZZ**, despite its dominance in volume, has a lower revenue efficiency. **XXX** also shows lower revenue per kg compared to **YYY**.\n",
    "\n",
    "3. **Interpretation**:\n",
    "   - The relationship between these graphs indicates that while **ZZZ** is the most frequently shipped, it is not the most profitable per unit weight. The high volume of **ZZZ** shipments likely targets bulk orders or less valuable products, which explains its lower revenue per kg. \n",
    "   - On the other hand, **YYY**, although shipped in smaller quantities, commands a much higher revenue per kilogram **(2.75 times more expensive per kilogram than ZZZ and 3.67 times more expensive per kilogram than XXX)**. \n",
    "   \n",
    "This suggests that **YYY** might be reserved for high-value or premium products, which justify the higher pricing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72475ec1",
   "metadata": {},
   "source": [
    "### Product Type analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart for average Price_per_kg by ProductCode\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Calculate the mean price per kg for each product code\n",
    "product_code_avg_price = new_df.groupby('ProductCode')['target'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Plot the bar chart\n",
    "ax = product_code_avg_price.plot(kind='bar', color='lightgreen')\n",
    "plt.title('Average Price per kg by ProductCode')\n",
    "plt.ylabel('Average Price per kg')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add the numbers on top of the bars\n",
    "for index, value in enumerate(product_code_avg_price):\n",
    "    plt.text(index, value, f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7512c8",
   "metadata": {},
   "source": [
    "The **average target value (revenue per kg)** for each product code shows significant variation across different product types:\n",
    "\n",
    "- The product code **XGH** has the highest average target value of 285, which is much greater than other products. This suggests that **XGH** may be an outlier, potentially biasing our analysis.\n",
    "- Other product codes, such as **SJD** and **X**, also have relatively high average target values, while **PCS** has the lowest.\n",
    "- The substantial difference between the highest and lowest average target values suggests that certain products may disproportionately impact the overall revenue per kg.\n",
    "\n",
    "To ensure the robustness of our model, it might be worth considering whether the extreme values, such as **XGH**, should be treated as outliers and possibly removed or further investigated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d473f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting the number of time we have the productcode XGH in our dataset \n",
    "# This helps identify how many times this outlier (product code \"XGH\") is repeated\n",
    "len(new_df.loc[new_df['ProductCode'] == \"XGH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54753bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to keep only the top 10 most shipped ProductCodes\n",
    "top_10_products = df['ProductCode'].value_counts().nlargest(20).index\n",
    "filtered_df = df[df['ProductCode'].isin(top_10_products)]\n",
    "plt.figure(figsize=(20, 10))\n",
    "ax = sns.countplot(data=filtered_df, x='FlownMonth', hue='ProductCode', palette='tab10')\n",
    "\n",
    "plt.title('Distribution of Top 10 ProductCodes per Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count of Product Shipped')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='ProductCode', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Annotating each bar with the count\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:  # Only annotate if there is a count\n",
    "        ax.text(\n",
    "            p.get_x() + p.get_width() / 2.,  # x position: center of the bar\n",
    "            height + 1,  # y position: just above the bar\n",
    "            f'{height}',  # the value to display\n",
    "            ha='center', va='bottom', fontsize=9, color='black'\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "revenue_per_product_per_month = new_df.groupby(['ProductCode', 'FlownMonth'])['Revenue'].sum().reset_index()\n",
    "\n",
    "# Find the top 10 product codes with the highest total revenue across all months\n",
    "top_10_products = revenue_per_product_per_month.groupby('ProductCode')['Revenue'].sum().nlargest(10).index\n",
    "\n",
    "# Filter the dataset to include only the top 10 product codes\n",
    "top_10_revenue_per_product_per_month = revenue_per_product_per_month[revenue_per_product_per_month['ProductCode'].isin(top_10_products)]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=top_10_revenue_per_product_per_month, x='FlownMonth', y='Revenue', hue='ProductCode')\n",
    "plt.title('Revenue by Top 10 Product Codes for Each Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Revenue')\n",
    "plt.legend(title='ProductCode', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "average_weights = df.groupby('ProductCode')['ChargeableWeight'].mean().reset_index()\n",
    "\n",
    "# Sort the average weights in descending order (heaviest to lightest)\n",
    "average_weights = average_weights.sort_values(by='ChargeableWeight', ascending=False)\n",
    "\n",
    "# Plotting the average weight for each product code\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(average_weights['ProductCode'], average_weights['ChargeableWeight'], color='skyblue')\n",
    "plt.xlabel('Product Code')\n",
    "plt.ylabel('Average Weight')\n",
    "plt.title('Average Weight per Product Code (Heaviest to Lightest)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598bb97",
   "metadata": {},
   "source": [
    "The plots above reveal key insights into product performance across different months:\n",
    "\n",
    "**Distribution of Top 10 Product Codes per Month:**\n",
    "- The product code **DLJ** is consistently the most shipped product across all months, with significantly higher shipment counts compared to other products.\n",
    "- Despite DLJ’s volume dominance, it does not generate the highest revenue, indicating it may be a lower-value or bulk product.\n",
    "\n",
    "**Revenue by Top 10 Product Codes for Each Month:**\n",
    "- The product code **MGK**, although shipped far less frequently than DLJ, generates the most revenue across all months \n",
    "ps: MGK 48.91% more expensive than DLJ [((13.62-9.15)/9.15)  *100] (we get the information from the graph showing the average price per kg per product code )\n",
    "\n",
    "\n",
    "These observations highlight that while DLJ dominates in terms of shipment volume but MGK is the primary driver of revenue. This contrast suggests that different strategies may be needed to manage each product type effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e934b61a",
   "metadata": {},
   "source": [
    "### Agents shipping Analysis: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f691843",
   "metadata": {},
   "source": [
    "#### plot the top 30 agents with the highest average price per kg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227bc6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent_impact = new_df.groupby('AgentCode')['target'].mean().sort_values(ascending=False)\n",
    "#print(agent_impact.head(10))\n",
    "plt.figure(figsize=(10, 5))\n",
    "agent_impact[:30].plot(kind='bar', color='green')\n",
    "#titles and labels for better readability \n",
    "plt.title('average charge per kilogram by agent that owns the shipment')\n",
    "plt.xlabel('Month')\n",
    "plt.show()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.swarmplot(x='target', y='AgentCode', data=new_df, order=agent_impact[:15].index, palette='deep')\n",
    "plt.title('Individual Charges per Kilogram by Agent')\n",
    "plt.xlabel('Charge per Kilogram')\n",
    "plt.ylabel('Agent Code')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bc754f",
   "metadata": {},
   "source": [
    "### Analysis of Agent Charges per Kilogram\n",
    "\n",
    "The two visualizations provide insight into the charging patterns of various agents and how they impact the overall pricing strategy:\n",
    "\n",
    "1. **Average Charge per Kilogram by agent**:\n",
    "   - This graph shows the average charge per kilogram for each agent. It is clear that agent **GIKGZVO** has an exceptionally high average charge compared to other agents. This could indicate a specialization in high-value or premium cargo, leading to higher per kilogram rates.\n",
    "   - Other agents show significantly lower average charges, suggesting they handle more standard or bulk cargo that doesn’t command high pricing.\n",
    "\n",
    "2. **Individual Charges per Kilogram by agent**:\n",
    "   - The scatter plot reveals the distribution of individual charges per kilogram for each agent. It shows that while most agents maintain a relatively consistent and lower charge range, agent **GIKGZVO** has a few extreme high values, confirming its higher average rate.\n",
    "   - This variability indicates that some agents might have a mixed strategy, handling both high-value and standard shipments, while others stick to a consistent low-cost approach.\n",
    "   \n",
    "   \n",
    "**With GIKGZVO having a significantly higher value compared to other agents, it can be considered an outlier. Removing it from the dataset could potentially improve the model's performance by reducing the influence of extreme values, leading to a more generalized model that better represents the majority of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85157a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by AgentCode and FlownMonth to count shipments\n",
    "shipment_count_per_agent = new_df.groupby(['AgentCode', 'FlownMonth']).size().unstack(fill_value=0)\n",
    "\n",
    "# Find the top 10 agents with the highest total shipments\n",
    "top_10_agents_by_shipment = shipment_count_per_agent.sum(axis=1).nlargest(10).index\n",
    "\n",
    "# Filter the dataset to include only the top 10 agents by shipment count\n",
    "top_10_shipment_count = shipment_count_per_agent.loc[top_10_agents_by_shipment]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(top_10_shipment_count, cmap='YlGnBu', annot=True, fmt='d')\n",
    "plt.title('Total Shipments per Top 10 Agents by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Agent Code')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67702647",
   "metadata": {},
   "source": [
    "The heatmap visualizes the total shipments per month for the top 10 agents, showing a clear pattern:\n",
    "\n",
    "The agent VFZB6JC consistently leads in all three months (September, October, and November), making it the most important or dominant shipper among the agents. The number of shipments for VFZB6JC remains significantly higher than the other agents, indicating its prominent role in shipment volume throughout the period. This highlights VFZB6JC as a key player in the shipping network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa0e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter the dataset to include only the top 10 agents based on 'agent_impact'\n",
    "top_agents = agent_impact[:20].index\n",
    "filtered_df = new_df[new_df['AgentCode'].isin(top_agents)]\n",
    "\n",
    "# Plot 1: Types of products shipped by these agents\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(y='ProductCode', data=filtered_df, order=filtered_df['ProductCode'].value_counts().index, hue='AgentCode', palette='viridis')\n",
    "plt.title('Product Types Shipped by Top Agents')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Product Code')\n",
    "plt.legend(title='Agent Code', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Types of cargo used by these agents\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(y='CargoType', data=filtered_df, order=filtered_df['CargoType'].value_counts().index, \n",
    "              hue='AgentCode', palette='coolwarm')\n",
    "\n",
    "plt.title('Cargo Types Used by Top Agents')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Cargo Type')\n",
    "plt.legend(title='Agent Code', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Filtering the dataset to include the top 15 agents based on 'agent_impact'\n",
    "top_15_agents = agent_impact[:10].index\n",
    "filtered_df_top_15 = new_df[new_df['AgentCode'].isin(top_15_agents)]\n",
    "# Count the number of unique product types each agent ships\n",
    "product_count_per_agent = filtered_df_top_15.groupby('AgentCode')['ProductCode'].nunique().sort_values(ascending=False)\n",
    "\n",
    "# Plotting the adjusted bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "product_count_per_agent.plot(kind='barh', color='purple')\n",
    "plt.title('Number of Product Types Shipped by Top 15 Agents')\n",
    "plt.xlabel('Number of Product Types')\n",
    "plt.ylabel('Agent Code')\n",
    "plt.gca().invert_yaxis()  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bd5349",
   "metadata": {},
   "source": [
    "### Analysis of Agent HNHR0VO and Product MGK\n",
    "\n",
    "- **HNHR0VO** exclusively ships **MGK**, which is in the **top 10 most expensive products**.\n",
    "- HNHR0VO ranks among the **top 10 most expensive agents**, likely due to handling only high-value shipments.\n",
    "- **DLJ** is the most shipped product but generates less revenue compared to MGK, reflecting its bulk/low-value nature.\n",
    "- **SJD** follows a similar trend, being shipped by multiple agents with lower specialization and costs.\n",
    "\n",
    "**Key Insight**: HNHR0VO's premium pricing aligns with MGK's high value, while DLJ's bulk strategy shows volume but less revenue impact.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.heatmap(new_df[['ChargeableWeight', 'Pieces', 'Revenue', 'target']].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43009bf4",
   "metadata": {},
   "source": [
    "The correlation heatmap shows that the current features do not have strong enough correlations to accurately predict the target, except for a moderate correlation with revenue. Therefore, feature engineering may be necessary to identify better predictors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d960dee6",
   "metadata": {},
   "source": [
    "# Feature engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03d3876",
   "metadata": {},
   "source": [
    "We are creating two new features as part of **feature engineering**:\n",
    "\n",
    "1. **Agent_Avg_Revenue**: This feature represents the average revenue generated by each agent. By including the average revenue per agent, we can capture the overall contribution of an agent to the revenue. This could help identify whether agents with higher average revenues have a consistent impact on pricing or profit margins, providing valuable insights into agent performance.\n",
    "\n",
    "2. **Agent_Total_Weight**: This feature represents the total chargeable weight managed by each agent. Adding the total weight helps us understand the scale of operations for each agent, which may influence the costs and pricing strategies. Agents handling more weight might benefit from economies of scale, which could impact the model.\n",
    "\n",
    "These engineered features will help provide a more nuanced understanding of each agent's impact on the target variable, potentially improving model performance by capturing relationships between agent-level metrics and shipment pricing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb6544",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_avg_revenue = new_df.groupby('AgentCode')['Revenue'].transform('mean')\n",
    "new_df['Agent_Avg_Revenue'] = agent_avg_revenue\n",
    "\n",
    "agent_total_weight = new_df.groupby('AgentCode')['ChargeableWeight'].transform('sum')\n",
    "new_df['Agent_Total_Weight'] = agent_total_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de69230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average price per kg for each ProductCode\n",
    "product_avg_price_per_kg = new_df.groupby('ProductCode')['target'].transform('mean')\n",
    "new_df['Product_Avg_Price_per_kg'] = product_avg_price_per_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1146e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_agent = LabelEncoder()\n",
    "label_encoder_product = LabelEncoder()\n",
    "label_encoder_flown = LabelEncoder()\n",
    "label_encoder_cargo = LabelEncoder()\n",
    "# Encode categorical features into numerical ones\n",
    "new_df['AgentCode_encoded'] = label_encoder_agent.fit_transform(new_df['AgentCode'])\n",
    "new_df['ProductCode_encoded'] = label_encoder_product.fit_transform(new_df['ProductCode'])\n",
    "new_df['FlownMonth_encoded'] = label_encoder_flown.fit_transform(new_df['FlownMonth'])\n",
    "new_df['CargoType_encoded'] = label_encoder_cargo.fit_transform(new_df['CargoType'])\n",
    "\n",
    "# Checking numerical columns after feature engineering\n",
    "numerical_columns = new_df.select_dtypes(include=['number']).columns\n",
    "print(pd.DataFrame(numerical_columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dfffb4",
   "metadata": {},
   "source": [
    "The new feature Product_Avg_Price_per_kg  provides the average price per kg for each product code helping us understand the typical revenue generated per unit weight for different products.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950d329",
   "metadata": {},
   "source": [
    "## Preparing the data for our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40db105",
   "metadata": {},
   "source": [
    "We are preparing the dataset for modeling by performing several important preprocessing steps. This includes removing outliers, which could bias the model, and encoding categorical features so they can be used effectively in a machine learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataset in case we need to preserve the original data\n",
    "dataset = new_df.copy()\n",
    "datasetout = new_df.copy()\n",
    "# Drop rows with outliers that could bias the model due to their large deviation from the mean\n",
    "dataset = dataset.drop(dataset[dataset['AgentCode'] == \"GIKGZVO\"].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e552a996",
   "metadata": {},
   "source": [
    "This is the **second correlation heatmap** we are creating, focusing on evaluating the impact of the newly engineered features alongside the original features. By including newly created variables like `Agent_Avg_Revenue`, `Agent_Total_Weight`, and encoded categorical features, we aim to observe whether these additions bring stronger correlations with the **target** variable. This analysis will help us determine if the new features are likely to be **important predictors** and thus enhance our model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8169f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(dataset[['ChargeableWeight', 'Pieces', 'Revenue', 'Agent_Avg_Revenue',\n",
    "       'Agent_Total_Weight', 'Product_Avg_Price_per_kg','AgentCode_encoded', \n",
    "                     'ProductCode_encoded','FlownMonth_encoded', 'CargoType_encoded','target']].corr(), \n",
    "            annot=True, \n",
    "            cmap='inferno')\n",
    "\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e01639f",
   "metadata": {},
   "source": [
    "The newly engineered features, **`Agent_Avg_Revenue`** and **`Product_Avg_Price_per_kg`**, seem to add value in predicting the target as they both exhibit relatively strong correlations (`0.69` and `0.17`, respectively).\n",
    "\n",
    "The encoded categorical features (**`AgentCode_encoded`**, **`ProductCode_encoded`**, **`FlownMonth_encoded`**) show **low correlation** with the target, meaning their direct impact is limited. However, these encoded features can still be useful for the model to identify relationships that might not be captured through simple correlation.\n",
    "\n",
    "The heatmap helps us understand that **feature engineering** added more explanatory power, especially with **`Agent_Avg_Revenue`**, and it will be an important factor to consider during model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9a28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not including revenue and cheargeable weight in X to avoid data leakeage \n",
    "X = dataset[['AgentCode_encoded', 'ProductCode_encoded', 'ChargeableWeight', 'Pieces', 'FlownMonth_encoded','Agent_Avg_Revenue', 'Agent_Total_Weight', 'Product_Avg_Price_per_kg', 'CargoType_encoded']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#in the next line of code we removed Agent_avg_revenue to see how worse our models were going to be\n",
    "#without this feature\n",
    "#and yes it indeed lowered our model performance by about 20%\n",
    "#at the end i still decided to keep it, but feel free to remove the # and re run the code to see \n",
    "#the difference without it on our models performance\n",
    "#X = dataset[['AgentCode_encoded', 'ProductCode_encoded', 'ChargeableWeight', 'Pieces', 'FlownMonth_encoded', 'Agent_Total_Weight', 'Product_Avg_Price_per_kg', 'CargoType_encoded']]\n",
    "\n",
    "y = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed66459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X and y but with the outlier GIKGZVO\n",
    "X_out = datasetout[['AgentCode_encoded', 'ProductCode_encoded', 'ChargeableWeight', 'Pieces', 'FlownMonth_encoded', 'Agent_Avg_Revenue', 'Agent_Total_Weight', 'Product_Avg_Price_per_kg', 'CargoType_encoded']]\n",
    "        \n",
    "#in the next line of code we removed Agent_avg_revenue to see how worse our models were going to be\n",
    "#without this feature\n",
    "#and yes it indeed lowered our model performance by about 20%\n",
    "#at the end i still decided to keep it, but feel free to remove the # and re run the code to see \n",
    "#the difference without it on our models performance\n",
    "                    \n",
    "#X_out = datasetout[['AgentCode_encoded', 'ProductCode_encoded', 'ChargeableWeight', 'Pieces', 'FlownMonth_encoded', 'Agent_Total_Weight', 'Product_Avg_Price_per_kg', 'CargoType_encoded']]\n",
    "y_out = datasetout['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.27, \n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_out, X_test_out, y_train_out, y_test_out = train_test_split(X_out, y_out, test_size=0.27, \n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae091cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries for our models \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c57ee2",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "We chose **Gradient Boosting Regressor**, **XGBoost Regressor**, and **Random Forest Regressor** due to the nature of our problem: predicting a continuous numeric value (regression task). These models are well-suited for regression because:\n",
    "\n",
    "- **Gradient Boosting Regressor** and **XGBoost**:\n",
    "  - Utilize boosting techniques to sequentially improve weak learners, creating a strong predictive model.\n",
    "  - Effectively capture complex, non-linear relationships in the data.\n",
    "  - Achieve high accuracy on complex datasets through optimization of loss functions.\n",
    "\n",
    "- **Random Forest Regressor**:\n",
    "  - Builds multiple decision trees and averages their predictions, reducing overfitting.\n",
    "  - Handles feature interactions well and provides a robust, ensemble-based solution.\n",
    "\n",
    "By comparing these models, we aim to identify the most effective one for our regression problem based on their performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb8f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries for model validation\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error ,r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026312f9",
   "metadata": {},
   "source": [
    "### Evaluation Metrics for Regression Models\n",
    "\n",
    "In evaluating the performance of regression models such as `GradientBoostingRegressor`, `XGBoost`, and `RandomForestRegressor`, it's crucial to choose metrics that provide meaningful insights into the model's predictive capabilities. The following metrics were selected:\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. R-squared (R²)\n",
    "\n",
    "- **Definition**: R² measures the proportion of variance in the dependent variable that is predictable from the independent variables.\n",
    "- **Why Choose R²?**\n",
    "  - **Interpretability**: It provides a clear indication of how well the independent variables explain the variability of the target variable.\n",
    "  - **Model Fit**: An R² value closer to 1 suggests a better fit, indicating that the model explains a large portion of the variance.\n",
    "  - **Comparative Analysis**: Useful for comparing the explanatory power of different models.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Root Mean Squared Error (RMSE)\n",
    "\n",
    "- **Definition**: RMSE is the square root of the average of squared differences between the predicted and actual values.\n",
    "- **Why Choose RMSE?**\n",
    "  - **Scale Sensitivity**: RMSE is in the same units as the target variable, making it easy to interpret the magnitude of errors.\n",
    "  - **Error Magnitude**: It penalizes larger errors more than smaller ones due to the squaring of differences, which is helpful when large errors are particularly undesirable.\n",
    "  - **Model Optimization**: Commonly used as a loss function for regression models, aiding in model tuning.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "####  3. Mean Absolute Error (MAE)\n",
    "\n",
    "- **Definition**: MAE calculates the average magnitude of errors between predicted and actual values, without considering their direction.\n",
    "- **Why MAE is Useful:**\n",
    "  - **Robustness to Outliers**: Unlike RMSE, MAE does not square the errors, so it is less sensitive to outliers.\n",
    "  - **Interpretability**: Provides a straightforward average error magnitude, which is easy to understand.\n",
    "  - **Balanced Error Perspective**: Offers a different viewpoint on model performance by treating all errors equally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d1998",
   "metadata": {},
   "source": [
    "## Evaluation Using train test split method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a14006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494cddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to train and evaluate a given model and return performance metrics without having to redo it for each model \n",
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    # Start measuring training time\n",
    "    start_time = time.time()  \n",
    "    \n",
    "    # Train the provided model on training data\n",
    "    model.fit(X_train, y_train)  \n",
    "    \n",
    "    # Calculate the total time taken to train the model\n",
    "    train_time = time.time() - start_time  \n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)  \n",
    "\n",
    "    # Calculate evaluation metrics: \n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Return the results as a dictionary for easy appending to the summary list\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2,\n",
    "        'Training Time (s)': train_time\n",
    "    }\n",
    "\n",
    "# Initialize an empty list to store the evaluation results of each model\n",
    "results = []\n",
    "\n",
    "# Example models to evaluate\n",
    "models = [\n",
    "    ('XGBoost', xgb.XGBRegressor(n_estimators=450, max_depth=4, learning_rate=0.1, random_state=42)),\n",
    "    ('Random Forest', RandomForestRegressor(n_estimators=500, max_depth=6, random_state=42)),\n",
    "    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=450, max_depth=4, learning_rate=0.1, random_state=42))\n",
    "]\n",
    "\n",
    "# Evaluate each model on both datasets\n",
    "for model_name, model in models:\n",
    "    # Evaluate on the dataset without the outlier\n",
    "    result = train_and_evaluate_model(model, X_train, y_train, X_test, y_test, model_name + ' (No Outlier)')\n",
    "    results.append(result)\n",
    "    \n",
    "    # Evaluate on the dataset with the outlier\n",
    "    result_out = train_and_evaluate_model(model, X_train_out, y_train_out, X_test_out, y_test_out, model_name + ' (With Outlier)')\n",
    "    results.append(result_out)\n",
    "\n",
    "# Convert results to a DataFrame for easier visualization\n",
    "results_dfi = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f7b0b3",
   "metadata": {},
   "source": [
    "We are defining a reusable function that takes a model, trains it, evaluates it, and returns the results. This function allows us to apply the same process consistently across different models while avoiding repetitive code. By using this function, we can easily track key metrics—such as training time, RMSE, MAE and R2 score**—for each model, and store these results in an organized way for later comparison. The use of an empty list (`results`) ensures that we can gather the metrics from each model to create a summary DataFrame that facilitates easy model evaluation and selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfda1e3",
   "metadata": {},
   "source": [
    "## Evaluation Using Cross-Validation\n",
    "To enhance the robustness of our evaluation, we now use cross-validation (with 5 folds) instead of a simple train-test split. This approach helps verify the stability and reliability of the models' performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0b7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a given model using cross-validation and return performance metrics\n",
    "def train_and_evaluate_model_cv(model, X, y, cv, model_name):\n",
    "    start_time = time.time()  \n",
    "    \n",
    "    # Cross-validation and get scores (negative MSE is converted to positive RMSE)\n",
    "    neg_mse_scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    rmse_scores = np.sqrt(-neg_mse_scores)\n",
    "    \n",
    "    # Calculate the average R2 score across all folds\n",
    "    r2_scores = cross_val_score(model, X, y, cv=cv, scoring='r2', n_jobs=-1)\n",
    "    \n",
    "    # Calculate the average MAE score across all folds\n",
    "    neg_mae_scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    mae_scores = -neg_mae_scores  # Convert negative MAE to positive\n",
    "\n",
    "    train_time = time.time() - start_time  \n",
    "\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Mean RMSE': rmse_scores.mean(),\n",
    "        'Std RMSE': rmse_scores.std(),\n",
    "        'Mean R2': r2_scores.mean(),\n",
    "        'Mean MAE': mae_scores.mean(),\n",
    "        'Std MAE': mae_scores.std(),\n",
    "        'Training Time (s)': train_time\n",
    "    }\n",
    "\n",
    "# Initialize an empty list to store the evaluation results of each model for cross-validation\n",
    "cv_results = []\n",
    "\n",
    "# Cross-validation setup (KFold with 5 splits)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate each model using cross-validation for both datasets\n",
    "for model_name, model in models:\n",
    "    # Evaluate on the dataset without the outlier\n",
    "    result_cv = train_and_evaluate_model_cv(model, X, y, kfold, model_name + ' (No Outlier)')\n",
    "    cv_results.append(result_cv)\n",
    "    \n",
    "    # Evaluate on the dataset with the outlier\n",
    "    result_cv_out = train_and_evaluate_model_cv(model, X_out, y_out, kfold, model_name + ' (With Outlier)')\n",
    "    cv_results.append(result_cv_out)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#models with fine-tuned parameters\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=450, max_depth=4, learning_rate=0.1, random_state=42)\n",
    "randomf_model = RandomForestRegressor(n_estimators=500, max_depth=6, random_state=42)\n",
    "grad_model = GradientBoostingRegressor(n_estimators=450, max_depth=4, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Models list\n",
    "models = [\n",
    "    ('XGBoost', xgb_model),\n",
    "    ('Random Forest', randomf_model),\n",
    "    ('Gradient Boosting', grad_model)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2904bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing out the result that we got for XGBOOST, RANDOM FOREST AND GRADIENT BOOSTING when we try \n",
    "#train_test_split method\n",
    "\n",
    "print(results_dfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6211a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing out the result that we got for XGBOOST, RANDOM FOREST AND GRADIENT BOOSTING when we try \n",
    "#cross_validation method\n",
    "\n",
    "\n",
    "print(cv_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_removed_feature = dataset[['AgentCode_encoded', 'ProductCode_encoded', 'ChargeableWeight', 'Pieces', 'FlownMonth_encoded', 'Agent_Total_Weight', 'Product_Avg_Price_per_kg', 'CargoType_encoded']]\n",
    "\n",
    "X_out_removed_feature = datasetout[['AgentCode_encoded', 'ProductCode_encoded', 'ChargeableWeight', 'Pieces', 'FlownMonth_encoded', 'Agent_Total_Weight', 'Product_Avg_Price_per_kg', 'CargoType_encoded']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rem, X_test_rem, y_train_rem, y_test_rem = train_test_split(X_removed_feature, y, test_size=0.27, \n",
    "                                                random_state=42)\n",
    "X_train_out_rem, X_test_out_rem, y_train_out_rem, y_test_out_rem = train_test_split(X_out_removed_feature, y_out, test_size=0.27, \n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0572f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to train and evaluate a given model and return performance metrics without having to redo it for each model \n",
    "def train_and_evaluate_model(model, X_train_rem, y_train_rem, X_test_rem, y_test_rem, model_name):\n",
    "    # Start measuring training time\n",
    "    start_time = time.time()  \n",
    "    \n",
    "    # Train the provided model on training data\n",
    "    model.fit(X_train, y_train)  \n",
    "    \n",
    "    # Calculate the total time taken to train the model\n",
    "    train_time = time.time() - start_time  \n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)  \n",
    "\n",
    "    # Calculate evaluation metrics: \n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Return the results as a dictionary for easy appending to the summary list\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2,\n",
    "        'Training Time (s)': train_time\n",
    "    }\n",
    "\n",
    "# Initialize an empty list to store the evaluation results of each model\n",
    "results = []\n",
    "\n",
    "# Example models to evaluate\n",
    "models = [\n",
    "    ('XGBoost', xgb.XGBRegressor(n_estimators=450, max_depth=4, learning_rate=0.1, random_state=42)),\n",
    "    ('Random Forest', RandomForestRegressor(n_estimators=500, max_depth=6, random_state=42)),\n",
    "    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=450, max_depth=4, learning_rate=0.1, random_state=42))\n",
    "]\n",
    "\n",
    "# Evaluate each model on both datasets\n",
    "for model_name, model in models:\n",
    "    # Evaluate on the dataset without the outlier\n",
    "    result = train_and_evaluate_model(model, X_train_rem, y_train_rem, X_test_rem, y_test_rem, model_name + ' (No Outlier)')\n",
    "    results.append(result)\n",
    "    \n",
    "    # Evaluate on the dataset with the outlier\n",
    "    result_out = train_and_evaluate_model(model, X_train_out, y_train_out, X_test_out, y_test_out, model_name + ' (With Outlier)')\n",
    "    results.append(result_out)\n",
    "\n",
    "# Convert results to a DataFrame for easier visualization\n",
    "results_df_rem = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ddaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model_cv(model, X, y, cv, model_name):\n",
    "    start_time = time.time()  \n",
    "    \n",
    "    # Cross-validation and get scores (negative MSE is converted to positive RMSE)\n",
    "    neg_mse_scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    rmse_scores = np.sqrt(-neg_mse_scores)\n",
    "    \n",
    "    # Calculate the average R2 score across all folds\n",
    "    r2_scores = cross_val_score(model, X, y, cv=cv, scoring='r2', n_jobs=-1)\n",
    "    \n",
    "    # Calculate the average MAE score across all folds\n",
    "    neg_mae_scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    mae_scores = -neg_mae_scores  # Convert negative MAE to positive\n",
    "\n",
    "    train_time = time.time() - start_time  \n",
    "\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Mean RMSE': rmse_scores.mean(),\n",
    "        'Std RMSE': rmse_scores.std(),\n",
    "        'Mean R2': r2_scores.mean(),\n",
    "        'Mean MAE': mae_scores.mean(),\n",
    "        'Std MAE': mae_scores.std(),\n",
    "        'Training Time (s)': train_time\n",
    "    }\n",
    "\n",
    "# Initialize an empty list to store the evaluation results of each model for cross-validation\n",
    "cv_results = []\n",
    "\n",
    "# Cross-validation setup (KFold with 5 splits)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate each model using cross-validation for both datasets\n",
    "for model_name, model in models:\n",
    "    # Evaluate on the dataset without the outlier\n",
    "    result_cv = train_and_evaluate_model_cv(model, X, y, kfold, model_name + ' (No Outlier)')\n",
    "    cv_results.append(result_cv)\n",
    "    \n",
    "    # Evaluate on the dataset with the outlier\n",
    "    result_cv_out = train_and_evaluate_model_cv(model, X_out_removed_feature, y_out, kfold, model_name + ' (With Outlier)')\n",
    "    cv_results.append(result_cv_out)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "cv_results_df_rem = pd.DataFrame(cv_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d71557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Model  Mean RMSE   Std RMSE   Mean R2  Mean MAE  \\\n",
      "0              XGBoost (No Outlier)  10.503596   1.440348  0.952765  2.039115   \n",
      "1            XGBoost (With Outlier)  39.002811  37.008528  0.669246  4.906595   \n",
      "2        Random Forest (No Outlier)  14.191151   3.980004  0.911826  3.360044   \n",
      "3      Random Forest (With Outlier)  51.030833  32.904589  0.345211  7.618718   \n",
      "4    Gradient Boosting (No Outlier)  10.261367   1.393032  0.955997  1.882719   \n",
      "5  Gradient Boosting (With Outlier)  55.452343  36.640594 -0.016429  4.555057   \n",
      "\n",
      "    Std MAE  Training Time (s)  \n",
      "0  0.206048           0.553916  \n",
      "1  1.343565           0.516893  \n",
      "2  0.548016          10.161563  \n",
      "3  0.979070           8.888461  \n",
      "4  0.183258           8.994852  \n",
      "5  1.205982           8.023459  \n"
     ]
    }
   ],
   "source": [
    "print(cv_results_df_rem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0404ee72",
   "metadata": {},
   "source": [
    "# EXPLANATION OF THE RESULTS CAN BE FOUND IN THE GIT IN A FILE UNDER THE NAME result_wiremind1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d27b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function tests the performance of the regression model by selecting a random row \n",
    "# from the dataset. It extracts the features and the true target value for that row, \n",
    "# makes a prediction using the trained model, and calculates the absolute error \n",
    "# between the predicted and true values. This helps us understand how well our model is \n",
    "# predicting individual instances from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "425f8ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Index: 2048\n",
      "True Value: 60.0\n",
      "Predicted Value: 60.512152231548015\n",
      "Absolute Error: 0.51\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine X and y to make it easier to select a random row\n",
    "dataset = X.copy()\n",
    "dataset['target'] = y\n",
    "\n",
    "# Function to select a random row and test the model for regression\n",
    "def test_random_row_regression(model, X, y):\n",
    "    # Select a random index from the dataset\n",
    "    random_index = np.random.randint(0, len(X))\n",
    "    \n",
    "    # Extract the random row and its true target value\n",
    "    random_row = X.iloc[random_index:random_index+1]\n",
    "    true_value = y.iloc[random_index]\n",
    "    \n",
    "    # Make a prediction using the model\n",
    "    predicted_value = model.predict(random_row)[0]\n",
    "    \n",
    "    # Calculate the absolute error (or any other metric you'd like)\n",
    "    absolute_error = abs(predicted_value - true_value)\n",
    "    \n",
    "    print(f\"Random Index: {random_index}\")\n",
    "    print(f\"True Value: {true_value}\")\n",
    "    print(f\"Predicted Value: {predicted_value}\")\n",
    "    print(f\"Absolute Error: {absolute_error:.2f}\")\n",
    "\n",
    "# Example usage\n",
    "test_random_row_regression(model, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89207511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
